# Lab 1 Report Summary

## Objective:
The primary goal of this lab was to develop proficiency in using PyTorch for both regression and multi-class classification tasks, employing Deep Neural Network (DNN) and Multi-Layer Perceptron (MLP) architectures.

## Part One: Regression
### Dataset:
- (https://www.kaggle.com/datasets/dgawlik/nyse)

### Work Completed:
1. **Exploratory Data Analysis (EDA):**
    - Conducted thorough EDA to understand dataset features and distributions.

2. **Deep Neural Network Architecture:**
    - Implemented a DNN architecture using PyTorch for regression, incorporating relevant features.

3. **Hyperparameter Tuning with GridSearch:**
    - Employed GridSearch from sklearn to optimize hyperparameters like learning rate, optimizers, and model architecture.

4. **Visualization:**
    - Generated graphs illustrating Loss vs. Epochs and Accuracy vs. Epochs for training and test data.
    - Provided interpretations of trends observed.

5. **Regularization Techniques:**
    - Applied various regularization techniques and compared results with the initial model.

## Part Two: Multi-Class Classification
### Dataset:
-  https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification

### Work Completed:
1. **Data Preprocessing:**
    - Performed data cleaning, standardization, and encoding of categorical variables.

2. **Exploratory Data Analysis (EDA):**
    - Analyzed dataset characteristics through EDA.

3. **Data Augmentation:**
    - Balanced dataset using data augmentation techniques.

4. **Deep Neural Network Architecture:**
    - Developed a PyTorch-based DNN architecture for multi-class classification.

5. **Hyperparameter Tuning with GridSearch:**
    - Leveraged GridSearch to optimize hyperparameters.

6. **Visualization:**
    - Visualized Loss vs. Epochs and Accuracy vs. Epochs for training and test data.
    - Interpreted trends observed.

7. **Metrics Calculation:**
    - Calculated accuracy, sensitivity, and F1 score on training and test datasets.

8. **Regularization Techniques:**
    - Applied regularization techniques and compared results with the initial model.

## Conclusion:
This lab provided hands-on experience in utilizing PyTorch for diverse tasks, emphasizing the importance of EDA, hyperparameter tuning, and model evaluation techniques. The comparison before and after regularization highlighted the impact of these techniques on model performance.
